import pandas as pd
import re
import time
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import WebDriverException, NoSuchElementException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup


# --- Fun√ß√£o de log ---
def registrar_log(mensagem: str):
    timestamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    with open("log.txt", "a", encoding="utf-8") as log_file:
        log_file.write(f"{timestamp} {mensagem}\n")


# --- Fun√ß√£o resetar log ---
def resetar_log():
    with open("log.txt", "w", encoding="utf-8") as log_file:
        log_file.write("")

# --- Recupera processos j√° processados do log ---
def obter_processos_processados():
    if not os.path.exists("log.txt"):
        return set()
    with open("log.txt", "r", encoding="utf-8") as f:
        linhas = f.readlines()
    return {linha.split("processo: ")[1].strip() for linha in linhas if "Iniciando scraping do processo:" in linha}


# --- Conectar ao navegador existente ---
def conectar_navegador_existente(porta: int = 9222):
    try:
        print(f"Tentando conectar ao navegador na porta {porta}...")
        opcoes_chrome = Options()
        opcoes_chrome.add_experimental_option("debuggerAddress", f"127.0.0.1:{porta}")

        navegador = webdriver.Chrome(options=opcoes_chrome)


        handles = navegador.window_handles
        print(handles)
        print("Current URL:", navegador.current_url)

        print("‚úÖ Conectado ao navegador existente com sucesso!")
        registrar_log("Conectado ao navegador com sucesso.")
        return navegador
    except WebDriverException:
        msg = "Erro ao conectar. Verifique se o Chrome est√° aberto com depura√ß√£o."
        print("‚ùå", msg)
        registrar_log(f"ERRO: {msg}")
        return None


# --- Ler processos v√°lidos ---
def ler_processos_validos(caminho_excel: str, nome_coluna: str = "processo"):
    df = pd.read_excel(caminho_excel)
    print(f'Planilha carregada com {len(df)} linhas.')
    padrao = re.compile(r"^\d{5}\.\d{6}\/\d{4}-\d{2}$")  # ex: 71000.037605/2025-61
    processos_validos = df[nome_coluna].dropna().astype(str)
    processos_filtrados = [proc for proc in processos_validos if padrao.match(proc)]
    print(f"üîç Total de processos v√°lidos encontrados: {len(processos_filtrados)}")
    registrar_log(f"{len(processos_filtrados)} processos v√°lidos encontrados.")
    return processos_filtrados


# --- Verificar autentica√ß√£o ---
def verificar_autenticacao(navegador):
    try:
        erro_autenticacao = navegador.find_elements(By.XPATH,
            "//*[contains(text(), 'Acesso Negado') or contains(text(), 'Sess√£o Expirada')]")
        if erro_autenticacao:
            registrar_log("‚ùå Sess√£o expirada ou acesso negado detectado.")
            return False
        return True
    except Exception as e:
        registrar_log(f"Erro ao verificar autentica√ß√£o: {e}")
        return False


# --- Extrair links e √°reas do processo ---
def extrair_links_processo(navegador, numero_processo):
        try:
            msg_inicio = f"Iniciando scraping do processo: {numero_processo}"
            registrar_log(msg_inicio)
            print(f"üîÑ {msg_inicio}")

            if not verificar_autenticacao(navegador):
                return [{
                    "processo": numero_processo,
                    "texto_link": "Erro: Sess√£o expirada ou acesso negado",
                    "SNEALIS": "",
                    "CGEALIS": "",
                    "CGFP": "",
                    "CGC": "",
                    "CGAP": ""
                }]

            navegador.switch_to.window(navegador.window_handles[0])
            wait = WebDriverWait(navegador, 10)
            campo_busca = wait.until(EC.presence_of_element_located((By.ID, "txtPesquisaRapida")))
            campo_busca.clear()
            campo_busca.send_keys(numero_processo)
            campo_busca.send_keys(Keys.ENTER)
            time.sleep(2)

            iframe = wait.until(EC.presence_of_element_located((By.ID, "ifrVisualizacao")))
            navegador.switch_to.frame(iframe)
            print("üîÅ Mudou para o iframe ifrVisualizacao.")

            try:
                div_arvore = wait.until(EC.presence_of_element_located((By.ID, "divArvoreHtml")))
            except:
                print(f"‚ö†Ô∏è Selenium falhou. Tentando BeautifulSoup para {numero_processo}")
                registrar_log(f"‚ö†Ô∏è Tentando BeautifulSoup para {numero_processo}")
                iframe_content = navegador.execute_script(
                    "return document.getElementById('ifrVisualizacao').contentDocument.body.innerHTML")
                soup = BeautifulSoup(iframe_content, 'html.parser')
                div_arvore_bs = soup.find("div", {"id": "divArvoreHtml"})

                if div_arvore_bs:
                    raw_text = div_arvore_bs.get_text(separator="\n").strip()
                    return [{
                        "processo": numero_processo,
                        "texto_link": raw_text,
                        "SNEALIS": "SNEALIS" if "SNEALIS" in raw_text else "",
                        "CGEALIS": "CGEALIS" if "CGEALIS" in raw_text else "",
                        "CGFP": "CGFP" if "CGFP" in raw_text else "",
                        "CGC": "CGC" if "CGC" in raw_text else "",
                        "CGAP": "CGAP" if "CGAP" in raw_text else ""
                    }]
                else:
                    return [{
                        "processo": numero_processo,
                        "texto_link": "Erro: divArvoreHtml n√£o encontrado (BS)",
                        "SNEALIS": "",
                        "CGEALIS": "",
                        "CGFP": "",
                        "CGC": "",
                        "CGAP": ""
                    }]

            # üîΩ FLUXO PRINCIPAL NORMAL DO SELENIUM üîΩ
            try:
                div_info = div_arvore.find_element(By.ID, "divInformacao")
                raw_text = div_info.get_attribute("innerText").strip()
            except NoSuchElementException:
                raw_text = div_arvore.get_attribute("innerText").strip()

            links = div_arvore.find_elements(By.XPATH, ".//a[@href]")
            resultados = []

            if links:
                for link in links:
                    try:
                        texto = link.text.strip()
                        href = link.get_attribute("href")
                        if texto and href:
                            texto_upper = texto.upper()  # For√ßa a compara√ß√£o ser case-insensitive

                            result = {
                                "processo": numero_processo,
                                "texto_link": texto,
                                "SNEALIS": "SNEALIS" if "SNEALIS" in texto_upper else "",
                                "CGEALIS": "CGEALIS" if "CGEALIS" in texto_upper else "",
                                "CGFP": "CGFP" if "CGFP" in texto_upper else "",
                                "CGC": "CGC" if "CGC" in texto_upper else "",
                                "CGAP": "CGAP" if "CGAP" in texto_upper else ""
                            }
                            print(f"Console Log - Processo {numero_processo}, Link: {result}")
                            resultados.append(result)
                    except Exception as e:
                        registrar_log(f"Erro ao processar link em {numero_processo}: {e}")
                        continue
                print(f"‚úÖ {len(resultados)} links encontrados para {numero_processo}")
                registrar_log(f"{len(resultados)} links encontrados para {numero_processo}.")
            else:
                print(f"‚ÑπÔ∏è Processo {numero_processo} sem links.")
                registrar_log(f"‚ÑπÔ∏è Processo {numero_processo} sem links.")
                resultados.append({
                    "processo": numero_processo,
                    "texto_link": raw_text,
                    "SNEALIS": "SNEALIS" if "SNEALIS" in raw_text else "",
                    "CGEALIS": "CGEALIS" if "CGEALIS" in raw_text else "",
                    "CGFP": "CGFP" if "CGFP" in raw_text else "",
                    "CGC": "CGC" if "CGC" in raw_text else "",
                    "CGAP": "CGAP" if "CGAP" in raw_text else ""
                })

            return resultados  # <- ESSENCIAL PARA O FLUXO NORMAL DO SELENIUM ‚úÖ

        except Exception as e:
            msg = f"‚ùå Erro no processo {numero_processo}: {e}"
            print(msg)
            registrar_log(msg)
            return [{
                "processo": numero_processo,
                "texto_link": f"Erro: {str(e)}",
                "SNEALIS": "",
                "CGEALIS": "",
                "CGFP": "",
                "CGC": "",
                "CGAP": ""
            }]


# --- Fun√ß√£o principal ---
def executar_scraping():
    def eta(indice):
        elapsed_time = time.time() - start_time

        # M√©dia por itera√ß√£o
        avg_time_per_iter = elapsed_time / indice

        # Estimativa de tempo restante
        remaining_iters = max_linha - indice
        eta_seconds = remaining_iters * avg_time_per_iter

        # Formata ETA como mm:ss
        eta_minutes = int(eta_seconds // 60)
        eta_secs = int(eta_seconds % 60)

        print(
            f"\n{indice} {'>' * 10} Porcentagem conclu√≠da:"
            f" {(indice / max_linha) * 100:.2f}% | ETA: {eta_minutes:02d}:{eta_secs:02d}\n")

    reset_log = input(str('Deseja resetar o log? [Y/n]'))
    if reset_log == 'Y':
        resetar_log()

    registrar_log("=== IN√çCIO DA EXECU√á√ÉO ===")
    navegador = conectar_navegador_existente()
    if not navegador:
        registrar_log("Execu√ß√£o abortada: navegador n√£o conectado.")
        return
    arquivo_fonte = (r'C:\Users\felipe.rsouza\OneDrive - Minist√©rio do Desenvolvimento e Assist√™ncia '
                  r'Social\Teste001\Processo_SEi bkp\baseDados_Formaliza√ß√£o_2024_SEi.xlsx')

    arquivo_destino = (
        r"C:\Users\felipe.rsouza\Minist√©rio do Desenvolvimento e Assist√™ncia Social\SNEAELIS - Power "
        r"BI\Formaliza√ß√£o\BaseDados_Formaliza√ß√£o_2024_SEi.xlsx"
    )

    processos_todos = ler_processos_validos(arquivo_fonte)
    max_linha = len(processos_todos) + 1

    processos_processados = obter_processos_processados()

    todos_os_resultados = []
    indice = 1
    for processo in processos_todos:
        eta(indice)
        if processo in processos_processados:
            print(f"üîÑ Ignorando {processo}.")
            continue

        print(f"üöÄ Executando: {processo}")
        resultado = extrair_links_processo(navegador, processo)
        todos_os_resultados.extend(resultado)

        # Exporta incrementalmente
        df_parcial = pd.DataFrame(todos_os_resultados)
        df_parcial.to_excel(arquivo_destino, index=False)

        indice += 1


    registrar_log("‚úÖ Execu√ß√£o finalizada com sucesso.")
    registrar_log("=== FIM DA EXECU√á√ÉO ===\n")


# --- Execu√ß√£o ---
if __name__ == "__main__":
    start_time = time.time()

    executar_scraping()